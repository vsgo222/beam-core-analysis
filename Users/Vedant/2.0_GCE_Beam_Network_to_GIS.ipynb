{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-27T15:33:44.871154Z",
     "end_time": "2023-04-27T15:33:45.610268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pycharm_project_316/BEAM_Freight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goyal/.virtualenvs/venv_lbl_gce/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_88299/4263173763.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point, LineString, Polygon\n",
    "\n",
    "# set the working directory\n",
    "BASE_DIR = Path.cwd()\n",
    "# print(BASE_DIR)\n",
    "\n",
    "#set the project directory\n",
    "project_folder = BASE_DIR.parent.parent\n",
    "print(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Upload output in the respective bucket storage in the following path\n",
    "# \"gs://beam-core-outputs/output/city_name/simulation_name/Output/*\" or\n",
    "# \"gs://beam-core-outputs/output/city_name/simulation_name/Output/plot/*\" or\n",
    "\n",
    "from google.cloud import storage\n",
    "# Upload file to Google Cloud service\n",
    "def upload_blob(_bucket_name, _source_file_name, _destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(_bucket_name)\n",
    "    blob = bucket.blob(_destination_blob_name)\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "    blob.upload_from_filename(_source_file_name, if_generation_match=generation_match_precondition)\n",
    "    print(\n",
    "        f\"File {_source_file_name} uploaded to {_destination_blob_name}.\"\n",
    "    )\n",
    "\n",
    "def delete_blob(_bucket_name, _blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(_bucket_name)\n",
    "    blob = bucket.blob(_blob_name)\n",
    "    generation_match_precondition = None\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to delete is aborted if the object's\n",
    "    # generation number does not match your precondition.\n",
    "    blob.reload()  # Fetch blob metadata to use in generation_match_precondition.\n",
    "    generation_match_precondition = blob.generation\n",
    "\n",
    "    blob.delete(if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(f\"Blob {_blob_name} deleted.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T15:33:44.926154Z",
     "end_time": "2023-04-27T15:33:45.610268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Basic Reference Points\n",
    "city_name=\"austin\"\n",
    "gcloud_bucket = \"gs://beam-core-outputs/output/austin\"\n",
    "iter_no = \"0\"\n",
    "linkstats_file_path = f\"{iter_no}.linkstats.csv.gz\"\n",
    "network_file_path = \"network.csv.gz\"\n",
    "event_files_path = f\"{iter_no}.events.csv.gz\"\n",
    "simulation_name = \"austin-base-with-freight-2018__2023-04-14_16-11-13_yoq\"\n",
    "analysis_type = \"Freight\"\n",
    "#Check if the folder exist, if not create it.\n",
    "try:\n",
    "    pathlib.Path(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\")).mkdir(parents=True, exist_ok=False)\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T15:33:45.012669Z",
     "end_time": "2023-04-27T15:33:45.610268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /tmp/pycharm_project_316/BEAM_Freight/Output/austin/austin-base-with-freight-2018__2023-04-14_16-11-13_yoq/Freight/plot/austin_Road_Network.png uploaded to output/austin/austin-base-with-freight-2018__2023-04-14_16-11-13_yoq/Output/plot/austin_Road_Network.png.\n"
     ]
    }
   ],
   "source": [
    "# read the network file and convert into featureclass\n",
    "# df_network = pd.read_csv(project_folder.joinpath(\"Data\", city_name, simulation_name,\"network.csv.gz\"), compression=\"gzip\", low_memory=True)\n",
    "df_network = pd.read_csv(f\"{gcloud_bucket}/{simulation_name}/{network_file_path}\", compression=\"gzip\", low_memory=True)\n",
    "df_network['geometry'] = df_network.apply(lambda x: LineString([(x['fromLocationX'], x['fromLocationY']) , (x['toLocationX'], x['toLocationY'])]), axis = 1)\n",
    "gdf_network = gpd.GeoDataFrame(df_network, geometry=df_network[\"geometry\"])\n",
    "gdf_network = gdf_network.set_crs(26910,allow_override=True)\n",
    "gdf_network.to_crs(4326, inplace=True) # convert to WGS1984\n",
    "# keep only selected columns\n",
    "col_to_keep = [\"linkId\",  \"linkLength\", \"linkFreeSpeed\", \"linkCapacity\", \"numberOfLanes\", \"linkModes\", \"attributeOrigId\", \"attributeOrigType\", \"geometry\"]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(30,30))\n",
    "gdf_network.to_crs(4326, inplace=True)\n",
    "gdf_network.plot(ax=ax,edgecolor='black',alpha= 0.4,)\n",
    "ax.axis('off')\n",
    "ax.set_title(f'{city_name} Road Network',fontsize=32)\n",
    "plt.tight_layout()\n",
    "plt_file_name=f\"{city_name}_Road_Network.png\"\n",
    "plt.savefig(project_folder.joinpath(\"Output\", city_name, simulation_name, \"Freight\", \"plot\", plt_file_name), dpi=600)\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\",plt_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/plot/{plt_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:09:54.653844Z",
     "end_time": "2023-04-26T20:10:36.942211Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gdf_network = gdf_network[col_to_keep]\n",
    "gpd_fc_file_name = \"beam_network_out.geojson\"\n",
    "gdf_network.to_file(project_folder.joinpath(\"Output\",city_name, simulation_name, analysis_type, gpd_fc_file_name), driver=\"GeoJSON\")\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{gpd_fc_file_name}\"\n",
    "\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:10:37.848272Z",
     "end_time": "2023-04-26T20:11:21.796121Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### clean up beam network and assign county ####"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:11:21.795121Z",
     "end_time": "2023-04-26T20:11:21.799159Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# intersect the road network with County file\n",
    "def intersect_county_rdntwrk(_gpdCT, _gpdrdntwrk):\n",
    "    _gpdCT.to_crs(3857, inplace=True) # set its projection to EPSG:3857\n",
    "    _gpdrdntwrk.to_crs(3857, inplace=True)\n",
    "    res_intersection = _gpdrdntwrk.overlay(_gpdCT, how='intersection')\n",
    "    res_intersection = res_intersection.to_crs(4326)\n",
    "    return res_intersection"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:11:21.798120Z",
     "end_time": "2023-04-26T20:11:21.844855Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "beam_network_out = gpd.read_file(project_folder.joinpath(\"Output\",city_name, simulation_name, analysis_type, \"beam_network_out.geojson\"))\n",
    "austin_boundary = gpd.read_file(project_folder.joinpath(\"Reference_Data\", city_name, \"Austin_Counties.geojson\"))\n",
    "# austin_boundary.set_crs(4326, inplace=True)\n",
    "\n",
    "col_to_keep = [\"linkId\",  \"linkLength\", \"linkFreeSpeed\", \"linkCapacity\", \"numberOfLanes\", \"linkModes\", \"attributeOrigId\", \"attributeOrigType\", \"geometry\",\"fromNodeId\",\"toNodeId\", \"name\", \"txdot_abbr\", \"fips_code\"]\n",
    "beam_network_splits = (intersect_county_rdntwrk(austin_boundary,beam_network_out)[col_to_keep])\n",
    "beam_network_splits = beam_network_splits.loc[beam_network_splits[\"linkLength\"]>0.001].copy()\n",
    "\n",
    "# overlay road network on counties and save the image\n",
    "fig, ax=plt.subplots(figsize=(30,30))\n",
    "# austin_boundary.plot(ax=ax,lw=0.7,edgecolor=\"black\")\n",
    "beam_network_splits.to_crs(4326, inplace=True)\n",
    "beam_network_splits.plot(ax=ax,column='name', categorical=True, cmap='Pastel2',legend=True,alpha= 0.8,)\n",
    "ax.axis('off')\n",
    "ax.set_title(f'BEAM Network Splits',fontsize=32)\n",
    "plt.tight_layout()\n",
    "plt_file_name=\"beam_network_splits.png\"\n",
    "plt.savefig(project_folder.joinpath(\"Output\", city_name, simulation_name, \"Freight\", \"plot\", plt_file_name), dpi=600)\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\",plt_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/plot/{plt_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:11:21.840856Z",
     "end_time": "2023-04-26T20:13:17.778039Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# export the dataframe\n",
    "gpd_fc_file_name = \"beam_network_by_county.geojson\"\n",
    "beam_network_splits.to_file(project_folder.joinpath(\"Output\",city_name, simulation_name, analysis_type, gpd_fc_file_name), driver=\"GeoJSON\")\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{gpd_fc_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:13:17.774532Z",
     "end_time": "2023-04-26T20:14:01.664009Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_file_name = \"beam_network_by_county.csv\"\n",
    "beam_network_splits.loc[:, ~beam_network_splits.columns.isin([\"geometry\"])].to_csv(project_folder.joinpath(\"Output\",city_name, simulation_name, analysis_type, df_file_name))\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, df_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{gpd_fc_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:14:01.661001Z",
     "end_time": "2023-04-26T20:14:03.541024Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import folium\n",
    "# m=folium.Map(location=[30.266666, -97.733330])\n",
    "# display_featureclass = folium.GeoJson(gdf_network.to_json()).add_to(m)\n",
    "# folium.LayerControl().add_to(m)\n",
    "# m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T20:14:03.591529Z",
     "end_time": "2023-04-26T20:14:03.592159Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:58:03.108433Z",
     "end_time": "2023-04-20T16:58:14.053328Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
