{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.646579Z",
     "end_time": "2023-04-27T16:20:29.707443Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import pygeos\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point, LineString, Polygon\n",
    "from collections import defaultdict\n",
    "\n",
    "# set the working directory\n",
    "BASE_DIR = Path.cwd()\n",
    "print(BASE_DIR)\n",
    "\n",
    "#set the project directory\n",
    "project_folder = BASE_DIR.parent.parent\n",
    "print(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Upload output in the respective bucket storage in the following path\n",
    "# \"gs://beam-core-outputs/output/city_name/simulation_name/Output/*\" or\n",
    "# \"gs://beam-core-outputs/output/city_name/simulation_name/Output/plot/*\" or\n",
    "\n",
    "from google.cloud import storage\n",
    "# Upload file to Google Cloud service\n",
    "def upload_blob(_bucket_name, _source_file_name, _destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(_bucket_name)\n",
    "    blob = bucket.blob(_destination_blob_name)\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "    blob.upload_from_filename(_source_file_name, if_generation_match=generation_match_precondition)\n",
    "    print(\n",
    "        f\"File {_source_file_name} uploaded to {_destination_blob_name}.\"\n",
    "    )\n",
    "\n",
    "def delete_blob(_bucket_name, _blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(_bucket_name)\n",
    "    blob = bucket.blob(_blob_name)\n",
    "    generation_match_precondition = None\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to delete is aborted if the object's\n",
    "    # generation number does not match your precondition.\n",
    "    blob.reload()  # Fetch blob metadata to use in generation_match_precondition.\n",
    "    generation_match_precondition = blob.generation\n",
    "\n",
    "    blob.delete(if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(f\"Blob {_blob_name} deleted.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.646579Z",
     "end_time": "2023-04-27T16:20:29.712453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Basic Reference Points\n",
    "city_name=\"austin\"\n",
    "gcloud_bucket = \"gs://beam-core-outputs/output/austin\"\n",
    "iter_no = \"0\"\n",
    "linkstats_file_path = f\"{iter_no}.linkstats.csv.gz\"\n",
    "network_file_path = \"network.csv.gz\"\n",
    "event_files_path = f\"{iter_no}.events.csv.gz\"\n",
    "simulation_name = \"austin-base-with-freight-2018__2023-04-14_16-11-13_yoq\"\n",
    "analysis_type = \"Freight\"\n",
    "#Check if the folder exist, if not create it.\n",
    "try:\n",
    "    pathlib.Path(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\")).mkdir(parents=True, exist_ok=False)\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:20:29.718453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# RADAR File location\n",
    "detector_location = gpd.read_file(project_folder.joinpath(\"Reference_Data\", city_name, \"RADAR\", \"detector_location.geojson\"))\n",
    "detector_location = detector_location.to_crs(3857) # set it to PCS instead of GCC\n",
    "\n",
    "# File location for the beam network created in previous notebook instance run\n",
    "beam_network = gpd.read_file(project_folder.joinpath(\"Output\", city_name, simulation_name, \"Freight\", \"beam_network_by_county.geojson\"))\n",
    "roadway_type = ['motorway','motorway_link','primary','primary_link','secondary','secondary_link','trunk','trunk_link','tertiary','tertiary_link']\n",
    "beam_network_with_cars = beam_network.loc[beam_network[\"attributeOrigType\"].isin(roadway_type)].copy()\n",
    "beam_network_with_cars = beam_network_with_cars.to_crs(3857)\n",
    "\n",
    "# intersect beam_network_with_cars with austin_npmrds_station, and keep only those links which has distance<50meter\n",
    "beam_network_with_radar = gpd.sjoin_nearest(beam_network_with_cars, detector_location, distance_col=\"distance_to_radar_stn\", max_distance=50)\n",
    "\n",
    "beam_network_with_radar = beam_network_with_radar.sort_values([\"linkId\", \"KITS_ID\", \"distance_to_radar_stn\"],ascending=[True, True, True]).drop_duplicates(subset=\"linkId\", keep=\"first\").copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:21.371147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(30,30))\n",
    "austin_boundary = gpd.read_file(project_folder.joinpath(\"Reference_Data\", city_name, \"Austin_Counties.geojson\"))\n",
    "austin_boundary = austin_boundary.to_crs(3857)\n",
    "austin_boundary.plot(ax=ax,lw=0.7,column='name', categorical=True, cmap='Pastel2',legend=True, legend_kwds={'fontsize':22,'frameon':False})\n",
    "beam_network_with_radar.to_crs(3857, inplace=True)\n",
    "beam_network_with_radar.plot(ax=ax,edgecolor='black',alpha= 0.4,lw=0.7)\n",
    "detector_location.to_crs(3857, inplace=True)\n",
    "detector_location.plot(ax=ax,marker=\"^\",markersize=75,alpha= 0.9, c= '#ffff00',)\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_title(f'{city_name.title()} BEAM Network RADAR Screenlines',fontsize=32)\n",
    "plt.tight_layout()\n",
    "plt_file_name=f\"{city_name.title()}_BEAM_network_Radar_Screenlines.png\"\n",
    "plt.savefig(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\", plt_file_name), dpi=600)\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\",plt_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/plot/{plt_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:37.117732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "gpd_fc_file_name = f\"{city_name.title() }_BEAM_Network_Radar_Screenlines.geojson\"\n",
    "beam_network_with_radar.to_file(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name), driver=\"GeoJSON\")\n",
    "\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{gpd_fc_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:37.611504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df_file_name = f\"{city_name.title() }_BEAM_Network_Radar_Screenlines.csv\"\n",
    "beam_network_with_radar.loc[:, ~beam_network_with_radar.columns.isin([\"geometry\"])].to_csv(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, df_file_name))\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, df_file_name)\n",
    "destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{df_file_name}\"\n",
    "# Check if the file exist in the bucket. If \"Yes\", delete\n",
    "try:\n",
    "    delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "except:\n",
    "    pass\n",
    "# and upload the file\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.031820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# # intersect beam network with RADAR station featureclass, keep records of only those features which are near to RADAR station location <=50 meter\n",
    "# dict_linkIds = defaultdict(list)\n",
    "# dict_radarIds = defaultdict(list)\n",
    "# for index, row in detector_location.iterrows():\n",
    "#     if isinstance(row.geometry, Point):\n",
    "#         beam_network_with_cars['Nearest_Point_distances'] = beam_network_with_cars.distance(row.geometry)\n",
    "#         lst_links = beam_network_with_cars.loc[beam_network_with_cars[\"Nearest_Point_distances\"]<=50][\"linkId\"].to_list()\n",
    "#         for link in lst_links:\n",
    "#             dict_linkIds.setdefault(link, []).append(row[\"KITS_ID\"])\n",
    "#             dict_radarIds.setdefault(row[\"KITS_ID\"], []).append(link)\n",
    "#\n",
    "# # convert the dictionary into a dataframe\n",
    "# dfNLinks4RadarStn = pd.concat({key: pd.Series(val) for key, val in dict_linkIds.items()},axis=1).transpose().reset_index()\n",
    "# # rename column heads\n",
    "# dfNLinks4RadarStn.rename(columns={\"index\":\"linkId\", 0:\"KITS_ID\"},inplace=True)\n",
    "# # Update the beam network features with nearest RADAR Station.\n",
    "# dictLinks = dict(zip(dfNLinks4RadarStn[\"linkId\"], (dfNLinks4RadarStn[\"KITS_ID\"])))\n",
    "# beam_network_with_radar = beam_network_with_cars.copy()\n",
    "# beam_network_with_radar[\"KITS_ID\"] = beam_network_with_radar[\"linkId\"].map(dictLinks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.035366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# # plot RADAR Station location\n",
    "# austin_boundary = gpd.read_file(project_folder.joinpath(\"Reference_Data\", city_name, \"Austin_Counties.geojson\"))\n",
    "# austin_boundary.to_crs(4326, inplace=True)\n",
    "#\n",
    "# fig, ax=plt.subplots(figsize=(30,30))\n",
    "# austin_boundary.plot(ax=ax,lw=0.7,column='name', categorical=True, cmap='Pastel2',legend=True, legend_kwds={'fontsize':22,'frameon':False})\n",
    "# beam_network_with_radar.to_crs(4326, inplace=True)\n",
    "# beam_network_with_radar.plot(ax=ax,edgecolor='black',alpha= 0.4,)\n",
    "# detector_location.to_crs(4326, inplace=True)\n",
    "# detector_location.plot(ax=ax,marker=\"^\",markersize=350,alpha= 0.9, c= '#ffff00',)\n",
    "#\n",
    "# ax.axis('off')\n",
    "# ax.set_title(f'{city_name} RADAR Station location',fontsize=32)\n",
    "# plt.tight_layout()\n",
    "# plt_file_name=f\"detector_location.png\"\n",
    "# plt.savefig(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, \"plot\", plt_file_name), dpi=600)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.042377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# # export the file as BEAM_network_screenlines.geojson\n",
    "# selected_beam_network_out = beam_network_with_radar.dropna(subset=[\"KITS_ID\"])\n",
    "# gpd_fc_file_name = \"BEAM_network_screenlines.geojson\"\n",
    "# selected_beam_network_out.to_file(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name), driver=\"GeoJSON\")\n",
    "# bucket_name = \"beam-core-outputs\"\n",
    "# source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, gpd_fc_file_name)\n",
    "# destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{gpd_fc_file_name}\"\n",
    "# # Check if the file exist in the bucket. If \"Yes\", delete\n",
    "# try:\n",
    "#     delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "# except:\n",
    "#     pass\n",
    "# # and upload the file\n",
    "# upload_blob(bucket_name, source_file_name, destination_blob_name)\n",
    "#\n",
    "# df_file_name = \"BEAM_network_screenlines.csv\"\n",
    "# selected_beam_network_out.loc[:, ~selected_beam_network_out.columns.isin([\"geometry\"])].to_csv(project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, df_file_name))\n",
    "# bucket_name = \"beam-core-outputs\"\n",
    "# source_file_name = project_folder.joinpath(\"Output\", city_name, simulation_name, analysis_type, df_file_name)\n",
    "# destination_blob_name = f\"output/{city_name}/{simulation_name}/Output/{df_file_name}\"\n",
    "# # Check if the file exist in the bucket. If \"Yes\", delete\n",
    "# try:\n",
    "#     delete_blob(_bucket_name=bucket_name, _blob_name=destination_blob_name)\n",
    "# except:\n",
    "#     pass\n",
    "# # and upload the file\n",
    "# upload_blob(bucket_name, source_file_name, destination_blob_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.049377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# # perform nearest neighbour analysis\n",
    "# def nearest_radar_point(x):\n",
    "#     dfRADARStn_geom = x\n",
    "#      # Calculating distance from the Point to SFChamp line FC\n",
    "#     beam_network_with_cars['Nearest_Point_distances'] = beam_network_with_cars.distance(dfRADARStn_geom)\n",
    "#\n",
    "#     fc_subset = (beam_network_with_cars.loc[beam_network_with_cars['Nearest_Point_distances']\n",
    "#                  .rank(method='first', ascending=True) <= 5]\n",
    "#                  .sort_values(by='Nearest_Point_distances', ascending=True))\n",
    "#     # pid = x[\"KITS_ID\"]\n",
    "#     # fid = fc_subset.loc[fc_subset[\"Nearest_Point_distances\"]<=5][\"linkId\"].to_list()\n",
    "#     # print(f\"{pid}: {fid}\")\n",
    "#     return fc_subset.index[fc_subset[\"Nearest_Point_distances\"]<=5].to_list()\n",
    "#\n",
    "#\n",
    "# detector_location[\"nearest_links\"]=\"\"\n",
    "# dict_linkids = dict()\n",
    "# for index, row in detector_location.iterrows():\n",
    "#     if isinstance(row.geometry, Point):\n",
    "#         dict_linkids[row[\"KITS_ID\"]] = nearest_radar_point(row.geometry)\n",
    "#         # row[\"Line_IDs\"] = nearest_links(row.geometry)\n",
    "#         # print(row[\"KITS_ID\"])\n",
    "#     else:\n",
    "#         continue\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.059381Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# dict_linkIds = defaultdict(list)\n",
    "# dict_radarIds = defaultdict(list)\n",
    "# for index, row in detector_location.iterrows():\n",
    "#     if isinstance(row.geometry, Point):\n",
    "#         beam_network_with_cars['Nearest_Point_distances'] = beam_network_with_cars.distance(row.geometry)\n",
    "#         lst_links = beam_network_with_cars.loc[beam_network_with_cars[\"Nearest_Point_distances\"]<=50][\"linkId\"].to_list()\n",
    "#         for link in lst_links:\n",
    "#             dict_linkIds.setdefault(link, []).append(row[\"KITS_ID\"])\n",
    "#             dict_radarIds.setdefault(row[\"KITS_ID\"], []).append(link)\n",
    "#\n",
    "#         # print(row[\"KITS_ID\"])\n",
    "#         # print(beam_network_with_cars.loc[beam_network_with_cars[\"Nearest_Point_distances\"]<=50][\"linkId\"].to_list())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.064387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# austin_boundary = gpd.read_file(project_folder.joinpath(\"Reference_Data\", city_name, \"Austin_Counties.geojson\"))\n",
    "# austin_boundary.to_crs(4326)\n",
    "#\n",
    "# fig, ax=plt.subplots(figsize=(30,30))\n",
    "# austin_boundary.plot(ax=ax,lw=0.7,column='name', categorical=True, cmap='Spectral',legend=True, legend_kwds={'fontsize':22,'frameon':False})\n",
    "# beam_network_with_radar.plot(ax=ax,edgecolor='black')\n",
    "# ax.axis('off')\n",
    "# ax.set_title(f'{city_name} RADAR detection location',fontsize=32)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(project_folder.joinpath(\"Output\", city_name, simulation_name, \"Freight\", \"plot\", \"austin_detector_location.png\"), dpi=600)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:20:29.647807Z",
     "end_time": "2023-04-27T16:21:38.066382Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
